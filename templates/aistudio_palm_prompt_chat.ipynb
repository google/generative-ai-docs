{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWIuwKG2_oWE"
      },
      "outputs": [],
      "source": [
        "# Install the client library and import necessary modules.\n",
        "!pip install google-generativeai\n",
        "import google.generativeai as palm\n",
        "import base64\n",
        "import json\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SvYoR3WCeKr"
      },
      "outputs": [],
      "source": [
        "# Configure the client library by providing your API key.\n",
        "palm.configure(api_key=\"YOUR API KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwab0i0RAHBN"
      },
      "outputs": [],
      "source": [
        "# These parameters for the model call can be set by URL parameters.\n",
        "model = \"\" # @param {isTemplate: true}\n",
        "temperature = 0.25 # @param {isTemplate: true}\n",
        "candidate_count = 1 # @param {isTemplate: true}\n",
        "top_k = 40 # @param {isTemplate: true}\n",
        "top_p = 0.95 # @param {isTemplate: true}\n",
        "context_b64 = '' # @param {isTemplate: true}\n",
        "examples_b64 = \"\"  # @param {isTemplate: true}\n",
        "messages_b64 = \"\"  # @param {isTemplate: true}\n",
        "\n",
        "defaults = {\n",
        "  'model': model,\n",
        "  'temperature': temperature,\n",
        "  'candidate_count': candidate_count,\n",
        "  'top_k': top_k,\n",
        "  'top_p': top_p,\n",
        "}\n",
        "\n",
        "# Convert the model context from a baese64 string to a string.\n",
        "context = base64.b64decode(context_b64).decode(\"utf-8\")\n",
        "\n",
        "# Convert the model inputs from base64 strings to lists.\n",
        "examples = json.loads(base64.b64decode(examples_b64).decode(\"utf-8\"))\n",
        "messages = json.loads(base64.b64decode(messages_b64).decode(\"utf-8\"))\n",
        "\n",
        "# Show what will be sent with the API call.\n",
        "pprint.pprint(defaults | {\n",
        "    'context': context, 'examples': examples, 'messages': messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB2LxPmAB95V"
      },
      "outputs": [],
      "source": [
        "# Call the model and print the response.\n",
        "response = palm.chat(\n",
        "  **defaults,\n",
        "  context=context,\n",
        "  examples=examples,\n",
        "  messages=messages\n",
        ")\n",
        "print(response.candidates[0]['content'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "aistudio_palm_prompt_chat.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
