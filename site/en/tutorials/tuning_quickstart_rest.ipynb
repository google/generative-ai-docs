{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# REST API: Tuning Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/tuning_quickstart_rest\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/tuning_quickstart_rest.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/tuning_quickstart_rest.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/tuning_quickstart_rest\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp_CKyzxUqx6"
      },
      "source": [
        "In this notebook, you'll learn how to get started with the Gemini API tuning service using curl commands or the Python request API to call the Gemini API. Here, you'll learn how to tune the text model behind the Gemini API's text generation service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCwzzSQqsNys"
      },
      "source": [
        "**Note**: At this time, tuning is only available for the `gemini-1.0-pro-001` model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSJSI1n7YNv2"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWxKvwd-MSIV"
      },
      "source": [
        "### Authenticate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjS8Zy1ojIgc"
      },
      "source": [
        "The Gemini API lets you tune models on your own data. Since it's your data and\n",
        "your tuned models this needs stricter access controls than API-Keys can provide.\n",
        "\n",
        "Before you can run this tutorial, you'll need to\n",
        "[setup OAuth for your project](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb).\n",
        "\n",
        "\n",
        "In Colab the easiest wat to get setup is to copy the contents of your `client_secret.json` file into Colab's \"Secrets manager\" (under the key icon in the left panel) with the secret name `CLIENT_SECRET`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NL1bBYUQ6Fs"
      },
      "source": [
        "This gcloud command turns the `client_secret.json` file into credentials that can be used to authenticate with the service.\n",
        "\n",
        "> Important: If you're running this in Colab, **don't just click the link it prints**. That will fail. Follow the instructions and copy the `gcloud` command it prints to your local machine and run it there, then paste the output from your local machine back here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FUwyB_MJ0-2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are authorizing client libraries without access to a web browser. Please run the following command on a machine with a web browser and copy its output back here. Make sure the installed gcloud version is 372.0.0 or newer.\n",
            "\n",
            "gcloud auth application-default login --remote-bootstrap=\"https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=87071151422-n1a3cb6c7fvkfg4gmhdtmn5ulol2l4be.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgenerative-language.tuning&state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&access_type=offline&code_challenge=76c1ZiGvKN8cvlYfj3BmbCwE4e7tvrlwaX3REUX25gY&code_challenge_method=S256&token_usage=remote\"\n",
            "\n",
            "\n",
            "Enter the output of the above command: https://localhost:8085/?state=QIyNibWSaTIsozjmvZEkVBo6EcoW0G&code=4/0AeaYSHBKrY911S466QjKQIFODoOPXlO1mWyTYYdrbELIDV6Hw2DKRAyro62BugroSvIWsA&scope=https://www.googleapis.com/auth/cloud-platform%20https://www.googleapis.com/auth/generative-language.tuning\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import userdata\n",
        "  import pathlib\n",
        "  pathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n",
        "\n",
        "  # Use `--no-browser` in colab\n",
        "  !gcloud auth application-default login --no-browser --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'\n",
        "except ImportError:\n",
        "  !gcloud auth application-default login --client-id-file client_secret.json --scopes='https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpe880lfchkp"
      },
      "source": [
        "## Calling the REST API with CURL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaSmQssJaMYV"
      },
      "source": [
        "This section gives example curl statements to call the REST API. You will learn how to create a tuning job, check its status and once complete, make an inference call."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1cQqdypn-Ga"
      },
      "source": [
        "### Set variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrbohImuJFGW"
      },
      "source": [
        "Set variables for recurring values to use for the rest of the REST API calls. The code is using the Python `os` library to set environment variables which is accessible in all the code cells.\n",
        "\n",
        "This is specific to the Colab notebook environment. The code in the next code cell is equivalent to running the following commands in a bash terminal.\n",
        "\n",
        "```bash\n",
        "export access_token=$(gcloud auth application-default print-access-token)\n",
        "export project_id=my-project-id\n",
        "export base_url=https://generativelanguage.googleapis.com\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZUa588km3Lx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "access_token = !gcloud auth application-default print-access-token\n",
        "access_token = '\\n'.join(access_token)\n",
        "\n",
        "os.environ['access_token'] = access_token\n",
        "os.environ['project_id'] = \"[Enter your project-id here]\"\n",
        "os.environ['base_url'] = \"https://generativelanguage.googleapis.com\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKeIDL44l7Q9"
      },
      "source": [
        "### List tuned models\n",
        "\n",
        "Verify your authentication setup by listing the currently available tuned models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAqw2D3vYWqm"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X GET ${base_url}/v1beta/tunedModels \\\n",
        "    -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer ${access_token}\" \\\n",
        "    -H \"x-goog-user-project: ${project_id}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MN52eRmyjN"
      },
      "source": [
        "### Create tuned model\n",
        "\n",
        "To create a tuned model, you need to pass your dataset to the model in the `training_data` field.\n",
        "\n",
        "For this example, you will tune a model to generate the next number in the sequence. For example, if the input is `1`, the model should output `2`. If the input is `one hundred`, the output should be `one hundred one`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBH2NaL6myDN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\": \"tunedModels/number-generator-model-dzlmi0gswwqb/operations/bvl8dymw0fhw\",\n",
            "  \"metadata\": {\n",
            "    \"@type\": \"type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata\",\n",
            "    \"totalSteps\": 38,\n",
            "    \"tunedModel\": \"tunedModels/number-generator-model-dzlmi0gswwqb\"\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2280    0   296  100  1984    611   4098 --:--:-- --:--:-- --:--:--  4720\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST $base_url/v1beta/tunedModels \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -H \"Authorization: Bearer ${access_token}\" \\\n",
        "    -H \"x-goog-user-project: ${project_id}\" \\\n",
        "    -d '\n",
        "      {\n",
        "        \"display_name\": \"number generator model\",\n",
        "        \"base_model\": \"models/gemini-1.0-pro-001\",\n",
        "        \"tuning_task\": {\n",
        "          \"hyperparameters\": {\n",
        "            \"batch_size\": 2,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"epoch_count\":5,\n",
        "          },\n",
        "          \"training_data\": {\n",
        "            \"examples\": {\n",
        "              \"examples\": [\n",
        "                {\n",
        "                    \"text_input\": \"1\",\n",
        "                    \"output\": \"2\",\n",
        "                },{\n",
        "                    \"text_input\": \"3\",\n",
        "                    \"output\": \"4\",\n",
        "                },{\n",
        "                    \"text_input\": \"-3\",\n",
        "                    \"output\": \"-2\",\n",
        "                },{\n",
        "                    \"text_input\": \"twenty two\",\n",
        "                    \"output\": \"twenty three\",\n",
        "                },{\n",
        "                    \"text_input\": \"two hundred\",\n",
        "                    \"output\": \"two hundred one\",\n",
        "                },{\n",
        "                    \"text_input\": \"ninety nine\",\n",
        "                    \"output\": \"one hundred\",\n",
        "                },{\n",
        "                    \"text_input\": \"8\",\n",
        "                    \"output\": \"9\",\n",
        "                },{\n",
        "                    \"text_input\": \"-98\",\n",
        "                    \"output\": \"-97\",\n",
        "                },{\n",
        "                    \"text_input\": \"1,000\",\n",
        "                    \"output\": \"1,001\",\n",
        "                },{\n",
        "                    \"text_input\": \"10,100,000\",\n",
        "                    \"output\": \"10,100,001\",\n",
        "                },{\n",
        "                    \"text_input\": \"thirteen\",\n",
        "                    \"output\": \"fourteen\",\n",
        "                },{\n",
        "                    \"text_input\": \"eighty\",\n",
        "                    \"output\": \"eighty one\",\n",
        "                },{\n",
        "                    \"text_input\": \"one\",\n",
        "                    \"output\": \"two\",\n",
        "                },{\n",
        "                    \"text_input\": \"three\",\n",
        "                    \"output\": \"four\",\n",
        "                },{\n",
        "                    \"text_input\": \"seven\",\n",
        "                    \"output\": \"eight\",\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }' | tee tunemodel.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad5ZWb_rmAst"
      },
      "source": [
        "### Get tuned model state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hre6xAdrRyS"
      },
      "source": [
        "The state of the model is set to `CREATING` during training and will change to `ACTIVE` once its complete.\n",
        "\n",
        "Below is a bit of python code to parse out the generated model name from the response JSON. If you're running this in a terminal you can try using a bash JSON parser to parse the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVs6r1j2YIuv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tunedModels/number-generator-model-dzlmi0gswwqb\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "first_page = json.load(open('tunemodel.json'))\n",
        "os.environ['modelname'] = first_page['metadata']['tunedModel']\n",
        "\n",
        "print(os.environ['modelname'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1urOyFnd7_N"
      },
      "source": [
        "  Do another `GET` request with the model name to get the model metadata which includes the state field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MdwY7duYmYL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \"state\": \"ACTIVE\",\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5921    0  5921    0     0  13164      0 --:--:-- --:--:-- --:--:-- 13157\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X GET ${base_url}/v1beta/${modelname} \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -H \"Authorization: Bearer ${access_token}\" \\\n",
        "    -H \"x-goog-user-project: ${project_id}\" | grep state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg8_cgelayQ5"
      },
      "source": [
        "### Run inference\n",
        "\n",
        "Once your tuning job is finished, you can use it to generate text with the text service. Try to input a Roman numeral, say, 63 (LXIII)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15ndxGP_cNBp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"candidates\": [\n",
            "    {\n",
            "      \"content\": {\n",
            "        \"parts\": [\n",
            "          {\n",
            "            \"text\": \"LXIV\"\n",
            "          }\n",
            "        ],\n",
            "        \"role\": \"model\"\n",
            "      },\n",
            "      \"finishReason\": \"STOP\",\n",
            "      \"index\": 0,\n",
            "      \"safetyRatings\": [\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        },\n",
            "        {\n",
            "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "          \"probability\": \"NEGLIGIBLE\"\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"promptFeedback\": {\n",
            "    \"safetyRatings\": [\n",
            "      {\n",
            "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "        \"probability\": \"NEGLIGIBLE\"\n",
            "      },\n",
            "      {\n",
            "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "        \"probability\": \"NEGLIGIBLE\"\n",
            "      },\n",
            "      {\n",
            "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "        \"probability\": \"NEGLIGIBLE\"\n",
            "      },\n",
            "      {\n",
            "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "        \"probability\": \"NEGLIGIBLE\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -X POST $base_url/v1beta/$modelname:generateContent \\\n",
        "    -H 'Content-Type: application/json' \\\n",
        "    -H \"Authorization: Bearer ${access_token}\" \\\n",
        "    -H \"x-goog-user-project: ${project_id}\" \\\n",
        "    -d '{\n",
        "        \"contents\": [{\n",
        "        \"parts\": [{\n",
        "          \"text\": \"LXIII\"\n",
        "          }]\n",
        "        }]\n",
        "        }' 2> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2zvbGFYeR18"
      },
      "source": [
        "The output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples. You can even create another tuned model based on the first one you created.\n",
        "\n",
        "See the [tuning guide](../guide/model_tuning_guidance) for more guidance on improving performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHWwC2dqXYUb"
      },
      "source": [
        "## Call the REST API with Python requests\n",
        "\n",
        "You can call the rest API with any library that allows you to send http requests.\n",
        "The next set of examples use the Python requests library, and demonstrates some of the  more advanced features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ0jOtfwaxU9"
      },
      "source": [
        "### Set variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_QXMiSlav_F"
      },
      "outputs": [],
      "source": [
        "access_token = !gcloud auth application-default print-access-token\n",
        "access_token = '\\n'.join(access_token)\n",
        "\n",
        "project = '[Enter your project-id here]'\n",
        "base_url = \"https://generativelanguage.googleapis.com\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWjmINASa-Tg"
      },
      "source": [
        "Import the `requests` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyjlnDjhYWoe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPtF6TiUhRr2"
      },
      "source": [
        "### List tuned models\n",
        "\n",
        "Verify your authentication setup by listing the currently available tuned models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r44T32P8ZiH4"
      },
      "outputs": [],
      "source": [
        "headers={\n",
        "  'Authorization': 'Bearer ' + access_token,\n",
        "  'Content-Type': 'application/json',\n",
        "  'x-goog-user-project': project\n",
        "}\n",
        "\n",
        "result = requests.get(\n",
        "  url=f'{base_url}/v1beta/tunedModels',\n",
        "  headers = headers,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC8lDO8uh1PY"
      },
      "outputs": [],
      "source": [
        "result.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_JVuo7hU8n"
      },
      "source": [
        "### Create tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4KrCiYITzXy"
      },
      "source": [
        "Same as for the Curl example, you pass in the dataset through the `training_data` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh4gcz6aaDzA"
      },
      "outputs": [],
      "source": [
        "operation = requests.post(\n",
        "    url = f'{base_url}/v1beta/tunedModels',\n",
        "    headers=headers,\n",
        "    json= {\n",
        "        \"display_name\": \"number generator\",\n",
        "        \"base_model\": \"models/gemini-1.0-pro-001\",\n",
        "        \"tuning_task\": {\n",
        "          \"hyperparameters\": {\n",
        "            \"batch_size\": 4,\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"epoch_count\":5,\n",
        "          },\n",
        "          \"training_data\": {\n",
        "            \"examples\": {\n",
        "              \"examples\": [\n",
        "                {\n",
        "                    'text_input': '1',\n",
        "                    'output': '2',\n",
        "                },{\n",
        "                    'text_input': '3',\n",
        "                    'output': '4',\n",
        "                },{\n",
        "                    'text_input': '-3',\n",
        "                    'output': '-2',\n",
        "                },{\n",
        "                    'text_input': 'twenty two',\n",
        "                    'output': 'twenty three',\n",
        "                },{\n",
        "                    'text_input': 'two hundred',\n",
        "                    'output': 'two hundred one',\n",
        "                },{\n",
        "                    'text_input': 'ninety nine',\n",
        "                    'output': 'one hundred',\n",
        "                },{\n",
        "                    'text_input': '8',\n",
        "                    'output': '9',\n",
        "                },{\n",
        "                    'text_input': '-98',\n",
        "                    'output': '-97',\n",
        "                },{\n",
        "                    'text_input': '1,000',\n",
        "                    'output': '1,001',\n",
        "                },{\n",
        "                    'text_input': '10,100,000',\n",
        "                    'output': '10,100,001',\n",
        "                },{\n",
        "                    'text_input': 'thirteen',\n",
        "                    'output': 'fourteen',\n",
        "                },{\n",
        "                    'text_input': 'eighty',\n",
        "                    'output': 'eighty one',\n",
        "                },{\n",
        "                    'text_input': 'one',\n",
        "                    'output': 'two',\n",
        "                },{\n",
        "                    'text_input': 'three',\n",
        "                    'output': 'four',\n",
        "                },{\n",
        "                    'text_input': 'seven',\n",
        "                    'output': 'eight',\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cMp2okEnIKR"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-scSZQ7aoqG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'tunedModels/number-generator-wl1qr34x2py/operations/41vni3zk0a47',\n",
              " 'metadata': {'@type': 'type.googleapis.com/google.ai.generativelanguage.v1beta.CreateTunedModelMetadata',\n",
              "  'totalSteps': 19,\n",
              "  'tunedModel': 'tunedModels/number-generator-wl1qr34x2py'}}"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "operation.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ymEe60etcsu"
      },
      "source": [
        "Set a variable with the name of your tuned model to use for the rest of the calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGyc1yWOCRMz"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tunedModels/number-generator-wl1qr34x2py'"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name=operation.json()[\"metadata\"][\"tunedModel\"]\n",
        "name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq1vdaK4hZEI"
      },
      "source": [
        "### Get tuned model state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO0Ms0K5hcWM"
      },
      "source": [
        "You can check the progress of your tuning job by checking the state field. `CREATING` means the tuning job is still ongoing and `ACTIVE` means the trainins is complete and the tuned model is ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms6u3X7vel12"
      },
      "outputs": [],
      "source": [
        "tuned_model = requests.get(\n",
        "    url = f'{base_url}/v1beta/{name}',\n",
        "    headers=headers,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohfKsMlYfH7m"
      },
      "outputs": [],
      "source": [
        "tuned_model.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbNjFRKaFbX"
      },
      "source": [
        "The code below checks the state field every 5 seconds until it is no longer in the `CREATING` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oleh5athmo-4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100.00% - {'step': 19, 'epoch': 5, 'meanLoss': 1.402067, 'computeTime': '2024-03-14T15:11:23.766989274Z'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pprint\n",
        "\n",
        "op_json = operation.json()\n",
        "response = op_json.get('response')\n",
        "error = op_json.get('error')\n",
        "\n",
        "while response is None and error is None:\n",
        "    time.sleep(5)\n",
        "\n",
        "    operation = requests.get(\n",
        "        url = f'{base_url}/v1/{op_json[\"name\"]}',\n",
        "        headers=headers,\n",
        "    )\n",
        "\n",
        "    op_json = operation.json()\n",
        "    response = op_json.get('response')\n",
        "    error = op_json.get('error')\n",
        "\n",
        "    percent = op_json['metadata'].get('completedPercent')\n",
        "    if percent is not None:\n",
        "      print(f\"{percent:.2f}% - {op_json['metadata']['snapshots'][-1]}\")\n",
        "      print()\n",
        "\n",
        "if error is not None:\n",
        "    raise Exception(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQRt4u1hIZ9a"
      },
      "source": [
        "### Run inference\n",
        "\n",
        "Once the tuning job is finished, you can use it to generate text in the same way you would use the base text model. Try to input a Japanese numeral, say, 6 (六)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVVrt-yiIZ9h"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "m = requests.post(\n",
        "    url = f'{base_url}/v1beta/{name}:generateContent',\n",
        "    headers=headers,\n",
        "    json= {\n",
        "         \"contents\": [{\n",
        "             \"parts\": [{\n",
        "                 \"text\": \"六\"\n",
        "             }]\n",
        "          }]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-cFTviPIZ9h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'candidates': [{'content': {'parts': [{'text': '七'}], 'role': 'model'},\n",
            "                 'finishReason': 'STOP',\n",
            "                 'index': 0,\n",
            "                 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
            "                                    'probability': 'NEGLIGIBLE'},\n",
            "                                   {'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
            "                                    'probability': 'NEGLIGIBLE'},\n",
            "                                   {'category': 'HARM_CATEGORY_HARASSMENT',\n",
            "                                    'probability': 'LOW'},\n",
            "                                   {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
            "                                    'probability': 'NEGLIGIBLE'}]}],\n",
            " 'promptFeedback': {'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n",
            "                                       'probability': 'NEGLIGIBLE'},\n",
            "                                      {'category': 'HARM_CATEGORY_HATE_SPEECH',\n",
            "                                       'probability': 'NEGLIGIBLE'},\n",
            "                                      {'category': 'HARM_CATEGORY_HARASSMENT',\n",
            "                                       'probability': 'NEGLIGIBLE'},\n",
            "                                      {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT',\n",
            "                                       'probability': 'NEGLIGIBLE'}]}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(m.json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI6PAEx4fN_M"
      },
      "source": [
        "The output from your model may or may not be correct. If the tuned model isn't performing up to your required standards, you can try adding more high quality examples, tweaking the hyperparameters or adding a preamble to your examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udu9f8CasVHe"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Even though the training data did not contain any reference to Roman or Japanese numerals, the model was able to generalize well after fine-tuning. This way, you can fine-tune models to cater to your use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRDAbJdYBXuj"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "To learn how to use the tuning service with the help of Python SDK for the Gemini API, visit the [tuning quickstart with Python](https://ai.google.dev/tutorials/tuning_quickstart_python). To learn how to use other services in the Gemini API, visit the [Python quickstart](https://ai.google.dev/tutorials/python_quickstart)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tuning_quickstart_rest.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
